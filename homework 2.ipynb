{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "neutral",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7e5dd04a-8d3d-4f60-b304-0c0b7c89660b",
       "rows": [
        [
         "0",
         "neutral",
         "Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said ."
        ],
        [
         "1",
         "negative",
         "The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily Postimees reported ."
        ],
        [
         "2",
         "positive",
         "With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability ."
        ],
        [
         "3",
         "positive",
         "According to the company 's updated strategy for the years 2009-2012 , Basware targets a long-term net sales growth in the range of 20 % -40 % with an operating profit margin of 10 % -20 % of net sales ."
        ],
        [
         "4",
         "positive",
         "FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is aggressively pursuing its growth strategy by increasingly focusing on technologically more demanding HDI printed circuit boards PCBs ."
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neutral</th>\n",
       "      <th>According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    neutral  \\\n",
       "0   neutral   \n",
       "1  negative   \n",
       "2  positive   \n",
       "3  positive   \n",
       "4  positive   \n",
       "\n",
       "  According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .  \n",
       "0  Technopolis plans to develop in stages an area...                                                                               \n",
       "1  The international electronic industry company ...                                                                               \n",
       "2  With the new production plant the company woul...                                                                               \n",
       "3  According to the company 's updated strategy f...                                                                               \n",
       "4  FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...                                                                               "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"HW1/FPB.csv\"\n",
    "fpb = pd.read_csv(file_path, encoding=\"ISO-8859-1\")\n",
    "fpb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for clarity\n",
    "fpb.columns = [\"Sentiment\", \"Headline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt') # downloads you a model\n",
    "\n",
    "nltk.download('stopwords') # <--- this is new\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# print(stop)\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import PorterStemmer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer() \n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "# return a list of tokens\n",
    "def pre_processing_by_nltk1(doc, stemming = False, need_sent = False):\n",
    "    # step 1: get sentences\n",
    "    sentences = sent_tokenize(doc)\n",
    "    # step 2: get tokens\n",
    "    tokens = []\n",
    "    for sent in sentences:\n",
    "        words = word_tokenize(sent)\n",
    "        # step 3 (optional): stemming\n",
    "        if stemming:\n",
    "            words = [ps.stem(word) for word in words]\n",
    "        if need_sent:\n",
    "            tokens.append(words)\n",
    "        else:\n",
    "            tokens += words\n",
    "    return [w.lower() for w in tokens if w.lower() not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [technopolis, plans, develop, stages, area, le...\n",
       "1    [international, electronic, industry, company,...\n",
       "2    [new, production, plant, company, would, incre...\n",
       "3    [according, company, 's, updated, strategy, ye...\n",
       "4    [financing, aspocomp, 's, growth, aspocomp, ag...\n",
       "Name: Headline, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpb.Headline[:5].apply(pre_processing_by_nltk1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a\n",
    "For each of the following words: production, profit, acquisition, investment, job, re-\n",
    "port the 10 most similar words based on word2vec and GloVe. Briefly discuss which method seems\n",
    "more reasonable to you or any other findings. Note: This is an open-ended question. Feel free to\n",
    "propose new ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbor Search\n",
    "\n",
    "- Most similar words based on word embedding vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Production', 0.7706561088562012),\n",
       " ('output', 0.6554935574531555),\n",
       " ('producing', 0.6320029497146606),\n",
       " ('produc_tion', 0.623302698135376),\n",
       " ('pro_duction', 0.5794395208358765),\n",
       " ('producers', 0.5526612997055054),\n",
       " ('ouput', 0.5512783527374268),\n",
       " ('producton', 0.5293622016906738),\n",
       " ('produciton', 0.5268733501434326),\n",
       " ('Chapada_mine', 0.5146549344062805)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['production'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('profits', 0.8020025491714478),\n",
       " ('proft', 0.7426661252975464),\n",
       " ('pretax_profit', 0.6691470742225647),\n",
       " ('pretax_profits', 0.643925130367279),\n",
       " ('Profit', 0.6339422464370728),\n",
       " ('earnings', 0.6314975023269653),\n",
       " ('Profits', 0.5853961706161499),\n",
       " ('revenue', 0.5829346179962158),\n",
       " ('pretax', 0.5686764121055603),\n",
       " ('quarterly', 0.5639331936836243)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['profit'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('acquisitions', 0.7727051973342896),\n",
       " ('acquistion', 0.7558104991912842),\n",
       " ('acquisiton', 0.7446470856666565),\n",
       " ('acqusition', 0.6910087466239929),\n",
       " ('aquisition', 0.6902487874031067),\n",
       " ('Acquisition', 0.6753405928611755),\n",
       " ('transaction', 0.66414874792099),\n",
       " ('merger', 0.6581048369407654),\n",
       " ('divestiture', 0.6535748243331909),\n",
       " ('acquired', 0.634006917476654)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['acquisition'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('investments', 0.8098693490028381),\n",
       " ('investing', 0.7012243270874023),\n",
       " ('Investment', 0.6812148690223694),\n",
       " ('invesment', 0.6630898714065552),\n",
       " ('investor', 0.6319271326065063),\n",
       " ('invest', 0.6203395128250122),\n",
       " ('investors', 0.5946778655052185),\n",
       " ('equity', 0.5897506475448608),\n",
       " ('investement', 0.5615226626396179),\n",
       " ('Investments', 0.5592135787010193)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['investment'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jobs', 0.6262935996055603),\n",
       " ('Job', 0.567025899887085),\n",
       " ('BrokeAss_Blog_Need', 0.5589310526847839),\n",
       " ('work', 0.5102996826171875),\n",
       " ('daunting_Platoni', 0.5058081150054932),\n",
       " ('employment', 0.49385008215904236),\n",
       " ('monster.com', 0.4883536100387573),\n",
       " ('thankless_job', 0.46077287197113037),\n",
       " ('rsum', 0.45291033387184143),\n",
       " ('temping', 0.4513639807701111)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['job'], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_77635/2153979838.py:8: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  _ = glove2word2vec(glove_file, tmp_file)\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_file = 'lecture3/glove.6B/glove.6B.100d.txt'\n",
    "tmp_file = get_tmpfile(\"test_word2vec.txt\")\n",
    "\n",
    "_ = glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('producing', 0.7758312821388245),\n",
       " ('output', 0.7606295943260193),\n",
       " ('produced', 0.755420446395874),\n",
       " ('producer', 0.7116324305534363),\n",
       " ('manufacturing', 0.7111999988555908),\n",
       " ('produce', 0.7051300406455994),\n",
       " ('producers', 0.695489764213562),\n",
       " ('product', 0.6899324059486389),\n",
       " ('sales', 0.6748071908950806),\n",
       " ('export', 0.6692141890525818)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['production'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('profits', 0.9010801315307617),\n",
       " ('earnings', 0.8935472965240479),\n",
       " ('net', 0.811954140663147),\n",
       " ('revenue', 0.8099523186683655),\n",
       " ('sales', 0.7789346575737),\n",
       " ('pretax', 0.767246425151825),\n",
       " ('quarter', 0.7604365348815918),\n",
       " ('revenues', 0.7518145442008972),\n",
       " ('share', 0.7449917197227478),\n",
       " ('gains', 0.7411855459213257)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['profit'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('merger', 0.8050162196159363),\n",
       " ('purchase', 0.7910113334655762),\n",
       " ('transaction', 0.7655937075614929),\n",
       " ('acquisitions', 0.749650776386261),\n",
       " ('sale', 0.7254613041877747),\n",
       " ('venture', 0.7206994295120239),\n",
       " ('company', 0.7177446484565735),\n",
       " ('acquire', 0.699617326259613),\n",
       " ('takeover', 0.6969232559204102),\n",
       " ('stake', 0.6833579540252686)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['acquisition'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('investments', 0.8891236782073975),\n",
       " ('fund', 0.7843336462974548),\n",
       " ('asset', 0.7737514972686768),\n",
       " ('financial', 0.7671132683753967),\n",
       " ('firms', 0.7522855997085571),\n",
       " ('equity', 0.7512969970703125),\n",
       " ('funds', 0.7471414804458618),\n",
       " ('business', 0.7369351983070374),\n",
       " ('portfolio', 0.7345483303070068),\n",
       " ('sector', 0.7308830618858337)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['investment'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jobs', 0.7932984232902527),\n",
       " ('better', 0.7354214191436768),\n",
       " ('doing', 0.7352380156517029),\n",
       " ('working', 0.7307748198509216),\n",
       " ('work', 0.7281291484832764),\n",
       " ('hiring', 0.7160316705703735),\n",
       " ('good', 0.7088245153427124),\n",
       " ('done', 0.7070804834365845),\n",
       " ('going', 0.7031288146972656),\n",
       " ('now', 0.6979781985282898)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['job'], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to construct sentence embedding from word embedding is to average the\n",
    "embedding of all words in a sentence, then you will get a 1D vector for each sentence. In this way,\n",
    "the order of words does not matter. Here we provide some pairs of sentences, calculate the cosine\n",
    "similarity of these sentences and give a brief discussion on whether these similarities are reasonable\n",
    "or not. What are the disadvantages of averaging word vectors for the document representation that\n",
    "you observe? Describe an idea to improve. Note: This is an open-ended question. Feel free to\n",
    "propose new ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average word embedding for a doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a, b):\n",
    "    return dot(a, b)/(norm(a)*norm(b))\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def doc2vec(doc, wv):\n",
    "    vecs = []\n",
    "    for token in doc.split():\n",
    "        try:\n",
    "            vecs.append(wv[token])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return np.mean(vecs, axis=0)\n",
    "\n",
    "doc1 = 'This movie is not bad and I would say I do enjoy it.'\n",
    "doc2 = 'This movie is bad and I would say I do not enjoy it.'\n",
    "\n",
    "doc3 = 'David is a cricket player and a opening batsman.'\n",
    "doc4 = 'Leo is a cricket player too. He is a batsman, baller and keeper.'\n",
    "\n",
    "doc5 = 'I love horror movies.'\n",
    "doc6 = 'Lights out is a horror movie.'\n",
    "\n",
    "v1 = doc2vec(doc1, wv)\n",
    "v2 = doc2vec(doc2, wv)\n",
    "v3 = doc2vec(doc3, wv)\n",
    "v4 = doc2vec(doc4, wv)\n",
    "v5 = doc2vec(doc5, wv)\n",
    "v6 = doc2vec(doc6, wv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80156016"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(v3, v4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55689824"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(v5, v6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above averaging word embedding method, and construct the feature matrix for the\n",
    "dataset with GloVe and word2vec word vectors, respectively. Feed the text classifier with a feature\n",
    "matrix, and re-run the text classification pipeline. Compare and analyze their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert a document to a vector by averaging word vectors\n",
    "def doc2vec(doc, wv):\n",
    "    vecs = [wv[word] for word in doc.split() if word in wv]\n",
    "    return np.mean(vecs, axis=0) if vecs else np.zeros(100)  # Returns a zero vector if no valid words are found\n",
    "\n",
    "# Generate feature vectors using Word2Vec\n",
    "X_word2vec = np.array([doc2vec(sentence, wv) for sentence in fpb[\"Headline\"]])\n",
    "\n",
    "# Generate feature vectors using GloVe\n",
    "X_glove = np.array([doc2vec(sentence, model) for sentence in fpb[\"Headline\"]])\n",
    "\n",
    "# Extract labels\n",
    "y = fpb[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First, split into Train (80%) and Temp (20%)\n",
    "X_train_w2v, X_temp_w2v, y_train, y_temp = train_test_split(X_word2vec, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Then, split Temp (20%) into Validation (10%) and Test (10%)\n",
    "X_val_w2v, X_test_w2v, y_val, y_test = train_test_split(X_temp_w2v, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Repeat for GloVe\n",
    "X_train_glove, X_temp_glove, _, y_temp = train_test_split(X_glove, y, test_size=0.2, random_state=42)\n",
    "X_val_glove, X_test_glove, _, _ = train_test_split(X_temp_glove, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define hyperparameter search space\n",
    "param_grid = {\"C\": [7, 7.5, 8, 8.5, 9]}\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "logistic_model = LogisticRegression(max_iter=50000)\n",
    "\n",
    "# Perform grid search using F1 Macro score\n",
    "grid_search_w2v = GridSearchCV(logistic_model, param_grid, scoring=\"f1_macro\", n_jobs=-1)\n",
    "grid_search_glove = GridSearchCV(logistic_model, param_grid, scoring=\"f1_macro\", n_jobs=-1)\n",
    "\n",
    "# Fit models for Word2Vec and GloVe\n",
    "grid_search_w2v.fit(X_train_w2v, y_train)\n",
    "grid_search_glove.fit(X_train_glove, y_train)\n",
    "\n",
    "# Get the best `C` value for each model\n",
    "best_C_w2v = grid_search_w2v.best_params_[\"C\"]\n",
    "best_C_glove = grid_search_glove.best_params_[\"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_C_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_C_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=9, max_iter=50000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=9, max_iter=50000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=9, max_iter=50000)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train final model using best C for Word2Vec\n",
    "model_w2v = LogisticRegression(C=best_C_w2v, max_iter=50000)\n",
    "model_w2v.fit(X_train_w2v, y_train)\n",
    "\n",
    "# Train final model using best C for GloVe\n",
    "model_glove = LogisticRegression(C=best_C_glove, max_iter=50000)\n",
    "model_glove.fit(X_train_glove, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the best Word2Vec model\n",
    "y_pred_w2v = model_w2v.predict(X_test_w2v)\n",
    "y_pred_proba_w2v = model_w2v.predict_proba(X_test_w2v)\n",
    "\n",
    "# Make predictions using the best GloVe model\n",
    "y_pred_glove = model_glove.predict(X_test_glove)\n",
    "y_pred_proba_glove = model_glove.predict_proba(X_test_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Representation",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ROC AUC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Macro-F1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Micro-F1",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "509bb056-d106-46d1-931d-69d3a256f87d",
       "rows": [
        [
         "0",
         "Word2Vec",
         "0.888228701589763",
         "0.7708751995890483",
         "0.8"
        ],
        [
         "1",
         "GloVe",
         "0.8476377465139645",
         "0.6469618059966161",
         "0.7175257731958763"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Representation</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Macro-F1</th>\n",
       "      <th>Micro-F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>0.888229</td>\n",
       "      <td>0.770875</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GloVe</td>\n",
       "      <td>0.847638</td>\n",
       "      <td>0.646962</td>\n",
       "      <td>0.717526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Representation   ROC AUC  Macro-F1  Micro-F1\n",
       "0       Word2Vec  0.888229  0.770875  0.800000\n",
       "1          GloVe  0.847638  0.646962  0.717526"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "# Function to compute evaluation metrics\n",
    "def evaluate(y_true, y_pred, y_proba):\n",
    "    return {\n",
    "        \"ROC AUC\": roc_auc_score(y_true, y_proba, multi_class=\"ovr\"),\n",
    "        \"Macro-F1\": f1_score(y_true, y_pred, average=\"macro\"),\n",
    "        \"Micro-F1\": f1_score(y_true, y_pred, average=\"micro\")\n",
    "    }\n",
    "\n",
    "# Compute evaluation results\n",
    "results_w2v = evaluate(y_test, y_pred_w2v, model_w2v.predict_proba(X_test_w2v))\n",
    "results_glove = evaluate(y_test, y_pred_glove, model_glove.predict_proba(X_test_glove))\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame([\n",
    "    [\"Word2Vec\", results_w2v[\"ROC AUC\"], results_w2v[\"Macro-F1\"], results_w2v[\"Micro-F1\"]],\n",
    "    [\"GloVe\", results_glove[\"ROC AUC\"], results_glove[\"Macro-F1\"], results_glove[\"Micro-F1\"]]\n",
    "], columns=[\"Representation\", \"ROC AUC\", \"Macro-F1\", \"Micro-F1\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: N-gram Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we provide a few sentences. You will use these to fit a unigram language model. Report\n",
    "the P(w) for all possible words and punctuation. Note: You do not need to write code. This is\n",
    "mostly a mathematics question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'How about some major emerging economies?',\n",
    "    'Elephants are the largest living terrestrial animals in the world.',\n",
    "    'Weather derivatives are tradable commodities that protect business owners from future changes in the weather.',\n",
    "    'Most Sunday papers have comics, which children enjoy.',\n",
    "    'Da Vinci was brilliant in multiple fields!'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 5,\n",
       " '<s>': 5,\n",
       " 'How': 1,\n",
       " 'How <s>': 1,\n",
       " 'about': 1,\n",
       " 'about How': 1,\n",
       " 'some': 1,\n",
       " 'some about': 1,\n",
       " 'major': 1,\n",
       " 'major some': 1,\n",
       " 'emerging': 1,\n",
       " 'emerging major': 1,\n",
       " 'economies?': 1,\n",
       " 'economies? emerging': 1,\n",
       " '</s>': 5,\n",
       " '</s> economies?': 1,\n",
       " 'Elephants': 1,\n",
       " 'Elephants <s>': 1,\n",
       " 'are': 2,\n",
       " 'are Elephants': 1,\n",
       " 'the': 3,\n",
       " 'the are': 1,\n",
       " 'largest': 1,\n",
       " 'largest the': 1,\n",
       " 'living': 1,\n",
       " 'living largest': 1,\n",
       " 'terrestrial': 1,\n",
       " 'terrestrial living': 1,\n",
       " 'animals': 1,\n",
       " 'animals terrestrial': 1,\n",
       " 'in': 3,\n",
       " 'in animals': 1,\n",
       " 'the in': 2,\n",
       " 'world.': 1,\n",
       " 'world. the': 1,\n",
       " '</s> world.': 1,\n",
       " 'Weather': 1,\n",
       " 'Weather <s>': 1,\n",
       " 'derivatives': 1,\n",
       " 'derivatives Weather': 1,\n",
       " 'are derivatives': 1,\n",
       " 'tradable': 1,\n",
       " 'tradable are': 1,\n",
       " 'commodities': 1,\n",
       " 'commodities tradable': 1,\n",
       " 'that': 1,\n",
       " 'that commodities': 1,\n",
       " 'protect': 1,\n",
       " 'protect that': 1,\n",
       " 'business': 1,\n",
       " 'business protect': 1,\n",
       " 'owners': 1,\n",
       " 'owners business': 1,\n",
       " 'from': 1,\n",
       " 'from owners': 1,\n",
       " 'future': 1,\n",
       " 'future from': 1,\n",
       " 'changes': 1,\n",
       " 'changes future': 1,\n",
       " 'in changes': 1,\n",
       " 'weather.': 1,\n",
       " 'weather. the': 1,\n",
       " '</s> weather.': 1,\n",
       " 'Most': 1,\n",
       " 'Most <s>': 1,\n",
       " 'Sunday': 1,\n",
       " 'Sunday Most': 1,\n",
       " 'papers': 1,\n",
       " 'papers Sunday': 1,\n",
       " 'have': 1,\n",
       " 'have papers': 1,\n",
       " 'comics,': 1,\n",
       " 'comics, have': 1,\n",
       " 'which': 1,\n",
       " 'which comics,': 1,\n",
       " 'children': 1,\n",
       " 'children which': 1,\n",
       " 'enjoy.': 1,\n",
       " 'enjoy. children': 1,\n",
       " '</s> enjoy.': 1,\n",
       " 'Da': 1,\n",
       " 'Da <s>': 1,\n",
       " 'Vinci': 1,\n",
       " 'Vinci Da': 1,\n",
       " 'was': 1,\n",
       " 'was Vinci': 1,\n",
       " 'brilliant': 1,\n",
       " 'brilliant was': 1,\n",
       " 'in brilliant': 1,\n",
       " 'multiple': 1,\n",
       " 'multiple in': 1,\n",
       " 'fields!': 1,\n",
       " 'fields! multiple': 1,\n",
       " '</s> fields!': 1}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_ngrams(corpus, n):\n",
    "    # collect C(w_{i-n+1}, .. w_i)\n",
    "    # collect C(w_{i-n+1}, .. w_{i-1})\n",
    "    counter = dict()\n",
    "    for sentence in corpus:\n",
    "        counter[''] = counter.get('', 0) + 1\n",
    "        tokens = sentence.split()\n",
    "        tokens = ['<s>'] + tokens + ['</s>']\n",
    "        # TODO: replace UNKNOWN tokens by <unk>\n",
    "        for i, token in enumerate(tokens):\n",
    "            combination = []\n",
    "            for j in range(i, max(0, i - n + 1) - 1, -1):\n",
    "                combination.append(tokens[j])\n",
    "                key = ' '.join(combination)\n",
    "                counter[key] = counter.get(key, 0) + 1\n",
    "    return counter\n",
    "\n",
    "counter = prepare_ngrams(corpus, 2)\n",
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have a unigram language model trained from the corpus. Use the model to calculate\n",
    "the probability of each following sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(counter, n, sentence):\n",
    "    tokens = sentence.split()\n",
    "    tokens = ['<s>'] + tokens + ['</s>']\n",
    "    # TODO: replace UNKNOWN tokens by <unk>\n",
    "    ret = 1\n",
    "    for i, token in enumerate(tokens):\n",
    "        comb = []\n",
    "        for j in range(i - 1, max(0, i - n + 1) - 1, -1):\n",
    "            comb.append(tokens[j])\n",
    "        # condition: w_{i - 1} ... w_{i - n + 1}\n",
    "        condition = ' '.join(comb)\n",
    "        comb = [token] + comb\n",
    "        full = ' '.join(comb)\n",
    "        # P(token | ... )\n",
    "        condition_count = counter.get(condition, 0)\n",
    "        if condition_count == 0:\n",
    "            prob = 0\n",
    "        else:\n",
    "            prob = counter.get(full, 0) / condition_count\n",
    "        print(full, '|', condition, prob)\n",
    "        ret *= prob\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc7 = 'She’d quickly look through the Greek story'\n",
    "doc8 = 'Older children don’t like being lectured at.'\n",
    "doc9 = 'Intangible assets are of growing importance in the emerging knowledge-based economy.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> |  1.0\n",
      "She’d <s> | <s> 0.0\n",
      "quickly She’d | She’d 0\n",
      "look quickly | quickly 0\n",
      "through look | look 0\n",
      "the through | through 0\n",
      "Greek the | the 0.0\n",
      "story Greek | Greek 0\n",
      "</s> story | story 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prob(counter, 2, doc7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> |  1.0\n",
      "Older <s> | <s> 0.0\n",
      "children Older | Older 0\n",
      "don’t children | children 0.0\n",
      "like don’t | don’t 0\n",
      "being like | like 0\n",
      "lectured being | being 0\n",
      "at. lectured | lectured 0\n",
      "</s> at. | at. 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prob(counter, 2, doc8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> |  1.0\n",
      "Intangible <s> | <s> 0.0\n",
      "assets Intangible | Intangible 0\n",
      "are assets | assets 0\n",
      "of are | are 0.0\n",
      "growing of | of 0\n",
      "importance growing | growing 0\n",
      "in importance | importance 0\n",
      "the in | in 0.6666666666666666\n",
      "emerging the | the 0.0\n",
      "knowledge-based emerging | emerging 0.0\n",
      "economy. knowledge-based | knowledge-based 0\n",
      "</s> economy. | economy. 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prob(counter, 2, doc9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can observe, zero probability exists. How would you deal with zero probabilities? Are\n",
    "they reasonable? Is there any way to overcome this issue? Make it an open-ended discussion.\n",
    "Note: This is an open-ended question. Feel free to propose new ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
